# ai-safety-price-challenge
A webapp for finding "bad" outputs of LLMs.
bad = prompts advocating violence 
